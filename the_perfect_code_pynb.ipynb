{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install pydub\n",
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rStGAjrt-exK",
        "outputId": "20ea46c8-7c00-46ce-f790-a9c9e2e5dc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=8c0e638417c1a997f00ade6e96cca95f391e162de9d3c84c96891726fbf596a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from moviepy.editor import VideoFileClip\n",
        "from pydub import AudioSegment\n",
        "from pydub.generators import Sine\n",
        "import torch\n",
        "\n",
        "# Step 1: Transcribe video using Whisper\n",
        "def transcribe_video(video_file):\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "    print(\"Transcribing video...\")\n",
        "    result = model.transcribe(video_file)\n",
        "    return result[\"text\"], result[\"segments\"]\n",
        "\n",
        "# Step 2: Detect profanity using RoBERTa\n",
        "def detect_profanity(text, tokenizer, model):\n",
        "    words = text.split()\n",
        "    profane_words = []\n",
        "    for word in words:\n",
        "        inputs = tokenizer(word, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        scores = torch.softmax(outputs.logits, dim=1).tolist()[0]\n",
        "        if scores[1] > 0.6:  # Threshold for profanity detection\n",
        "            profane_words.append(word)\n",
        "    return profane_words\n",
        "\n",
        "# Step 3: Generate beep sound\n",
        "def generate_beep(duration, frequency=1000):\n",
        "    return Sine(frequency).to_audio_segment(duration=duration * 1000)\n",
        "\n",
        "# Step 4: Add beep to profane word timestamps\n",
        "def add_beep_to_audio(audio_file, segments, profane_words, output_audio_file, buffer_ms=200):\n",
        "    print(\"Adding beeps to audio...\")\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    for segment in segments:\n",
        "        segment_start_time = segment[\"start\"] * 1000\n",
        "        segment_end_time = segment[\"end\"] * 1000\n",
        "\n",
        "        words = segment[\"text\"].split()\n",
        "        word_start_time = segment_start_time\n",
        "        word_duration = (segment_end_time - segment_start_time) / len(words)\n",
        "\n",
        "        for word in words:\n",
        "            word_end_time = word_start_time + word_duration\n",
        "            if word in profane_words:\n",
        "                # Calculate beep duration proportional to word duration plus buffer\n",
        "                beep_duration = (word_duration + 2 * buffer_ms) / 1000  # Convert ms to seconds\n",
        "                beep = generate_beep(duration=beep_duration)\n",
        "\n",
        "                # Adjust start and end times to include buffer for smoother beeping\n",
        "                beep_start = max(0, word_start_time - buffer_ms)\n",
        "                beep_end = min(len(audio), word_end_time + buffer_ms)\n",
        "\n",
        "                print(f\"Beeping word: {word} from {beep_start}ms to {beep_end}ms\")\n",
        "                audio = audio[:int(beep_start)] + beep + audio[int(beep_end):]\n",
        "\n",
        "            word_start_time = word_end_time\n",
        "\n",
        "    audio.export(output_audio_file, format=\"wav\")\n",
        "    print(f\"Modified audio saved to {output_audio_file}\")\n",
        "\n",
        "\n",
        "# Main function\n",
        "def process_video(video_file):\n",
        "    transcription_text, segments = transcribe_video(video_file)\n",
        "    print(\"Loading profanity detection model...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")\n",
        "    print(\"Detecting profane words...\")\n",
        "    profane_words = detect_profanity(transcription_text, tokenizer, model)\n",
        "    print(f\"Profane words detected: {profane_words}\")\n",
        "\n",
        "    audio_file = \"temp_audio.wav\"\n",
        "    modified_audio_file = \"modified_audio_with_beeps.wav\"\n",
        "    video = VideoFileClip(video_file)\n",
        "    video.audio.write_audiofile(audio_file, codec=\"pcm_s16le\")\n",
        "    add_beep_to_audio(audio_file, segments, profane_words, modified_audio_file)\n",
        "\n",
        "    os.remove(audio_file)\n",
        "\n",
        "# Run the process\n",
        "if __name__ == \"__main__\":\n",
        "    video_file = \"RAM.mp4\"  # Replace with your video file\n",
        "    process_video(video_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGseMNSnOWFC",
        "outputId": "904eff53-749a-4d10-8ec8-ad6f0ffe3e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing video...\n",
            "Loading profanity detection model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting profane words...\n",
            "Profane words detected: ['fucking', 'assholes!', 'Goddammit!', 'Goddammit!', 'dumb.', 'fucking', 'motherfucker?', 'fucking', 'Dammit.']\n",
            "MoviePy - Writing audio in temp_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Adding beeps to audio...\n",
            "Beeping word: fucking from 25660.0ms to 26270.0ms\n",
            "Beeping word: assholes! from 31586.666666666668ms to 32440.0ms\n",
            "Beeping word: Goddammit! from 42520.0ms to 43320.0ms\n",
            "Beeping word: Goddammit! from 44786.66666666667ms to 45520.00000000001ms\n",
            "Beeping word: dumb. from 129760.0ms to 130440.0ms\n",
            "Beeping word: fucking from 144160.0ms to 144840.0ms\n",
            "Beeping word: motherfucker? from 148968.0ms to 149680.0ms\n",
            "Beeping word: fucking from 156325.71428571432ms to 156937.1428571429ms\n",
            "Beeping word: Dammit. from 168680.0ms to 169387ms\n",
            "Modified audio saved to modified_audio_with_beeps.wav\n"
          ]
        }
      ]
    }
  ]
}